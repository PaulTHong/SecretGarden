<!DOCTYPE html>
<html>
<head>
<title>ht_note.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<!-- <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script> -->
<p><em>搬运工：保罗史蒂芬乔治洪 ~ paul.ht</em></p>
<p><strong>布局结构</strong>：</p>
<ul>
<li>Python
<ul>
<li>Pytorch</li>
<li>Tensorflow</li>
<li>Python</li>
<li>opencv2</li>
</ul>
</li>
<li>MATLAB</li>
<li>Linux</li>
<li>Mac</li>
<li>Markdown</li>
<li>LaTex</li>
<li>Others</li>
</ul>
<hr>
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->
<!-- code_chunk_output -->
<ul>
<li><a href="#python">Python</a>
<ul>
<li><a href="#pytorch">Pytorch</a>
<ul>
<li><a href="#tensor">Tensor</a></li>
<li><a href="#item">item()</a></li>
<li><a href="#torchvisiontransforms">torchvision.transforms</a></li>
<li><a href="#torchvisionsave_image">torchvision.save_image</a></li>
<li><a href="#relu">Relu</a></li>
<li><a href="#nnconvtranspose2d">nn.ConvTranspose2d</a></li>
<li><a href="#torchvision">torchvision</a></li>
<li><a href="#cv2%E7%9A%84%E5%9D%91">cv2的坑</a></li>
<li><a href="#%E8%B0%83%E8%8A%82%E5%AD%A6%E4%B9%A0%E7%8E%87">调节学习率</a></li>
<li><a href="#torchnndataparallel">torch.nn.DataParallel()</a></li>
<li><a href="#torchnndistributeddataparallel">torch.nn.DistributedDataParallel</a></li>
<li><a href="#num_worker">num_worker</a></li>
<li><a href="#multinomial">multinomial</a></li>
<li><a href="#load_lua-torchfileload">load_lua -&gt; torchfile.load</a></li>
</ul>
</li>
<li><a href="#tensorflow">Tensorflow</a>
<ul>
<li><a href="#tfsession">tf.Session()</a></li>
<li><a href="#tensorflow-%E4%B9%8B-checkpoint">tensorflow 之 checkpoint</a></li>
<li><a href="#%E9%80%89%E6%8B%A9gpu">选择GPU</a></li>
<li><a href="#tfnn">tf.nn</a></li>
<li><a href="#%E5%8D%B7%E7%A7%AF%E6%8E%A2%E8%AE%A8">卷积探讨</a></li>
<li><a href="#%E6%84%9F%E5%8F%97%E9%87%8E">感受野</a></li>
<li><a href="#resnet">ResNet</a></li>
<li><a href="#ncwh">(N,C,W,H)</a></li>
<li><a href="#%E4%BC%98%E5%8C%96%E5%99%A8">优化器</a></li>
<li><a href="#training-accuracy">training accuracy</a></li>
</ul>
</li>
<li><a href="#python-1">Python</a>
<ul>
<li><a href="#npclip">np.clip()</a></li>
<li><a href="#nprandomchoice">np.random.choice()</a></li>
<li><a href="#%E6%8E%92%E5%BA%8F">排序</a></li>
<li><a href="#zip">zip</a></li>
<li><a href="#eval">eval()</a></li>
<li><a href="#f-string">f-string</a></li>
<li><a href="#glob">glob</a></li>
<li><a href="#ospathdirname__file__">os.path.dirname(__file__)</a></li>
<li><a href="#argparse">argparse</a>
<ul>
<li><a href="#bool%E5%9E%8Bargparse-%E5%9D%91">bool型argparse 坑</a></li>
</ul>
</li>
<li><a href="#class">class</a></li>
<li><a href="#__call__">__call__()</a></li>
<li><a href="#__dir__">__dir__()</a></li>
<li><a href="#python%E5%87%BD%E6%95%B0%E4%BC%A0%E5%AF%B9%E8%B1%A1call-by-object">Python函数——传对象(call by object)</a></li>
<li><a href="#globals">globals()</a></li>
<li><a href="#zfill">zfill</a></li>
<li><a href="#ravel-flatten">ravel() &amp; flatten()</a></li>
<li><a href="#nprollaxis">np.rollaxis（）</a></li>
<li><a href="#matplotlib">matplotlib</a></li>
<li><a href="#pltplot">plt.plot()</a></li>
</ul>
</li>
<li><a href="#opencv2">opencv2</a>
<ul>
<li><a href="#resize">resize</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#matlab">MATLAB</a>
<ul>
<li><a href="#matlab-bsxfun">MATLAB bsxfun</a></li>
<li><a href="#python-%E4%B8%8E-matlab%E7%9A%84%E4%B8%80%E4%BA%9B%E5%87%BD%E6%95%B0%E5%8C%BA%E5%88%AB%E7%BB%86%E8%8A%82">Python 与 MATLAB的一些函数区别（细节）</a>
<ul>
<li><a href="#%E5%A4%8D%E6%95%B0%E5%9F%9F">复数域</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#linux">Linux</a>
<ul>
<li><a href="#bash">bash</a></li>
<li><a href="#adduser-useradd">adduser useradd</a></li>
<li><a href="#ls">ls</a></li>
<li><a href="#%E8%BD%AF%E9%93%BE%E6%8E%A5">软链接</a></li>
<li><a href="#ssh">ssh</a></li>
<li><a href="#%E6%9F%A5%E7%9C%8Bcpu-gpu%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5">查看CPU GPU使用情况</a></li>
<li><a href="#%E8%BE%93%E5%87%BA%E6%9C%BA%E5%88%B6">输出机制</a></li>
<li><a href="#export-echo">export &amp; echo</a></li>
<li><a href="#tar">tar</a></li>
<li><a href="#scp">scp</a></li>
<li><a href="#ctrl%E7%B1%BB%E5%BF%AB%E6%8D%B7%E9%94%AE">Ctrl类快捷键</a></li>
<li><a href="#%E6%9F%A5%E7%9C%8B%E4%BD%8D%E7%BD%AE">查看位置</a></li>
<li><a href="#linux%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E5%A4%A7%E5%B0%8F%E6%95%B0%E9%87%8F">Linux查看文件大小数量</a></li>
<li><a href="#linux-%E6%9F%A5%E7%9C%8B%E7%A1%AC%E7%9B%98%E5%88%86%E5%8C%BA%E5%86%85%E5%AD%98">Linux 查看硬盘分区内存</a></li>
<li><a href="#%E6%9F%A5%E7%9C%8B%E6%9D%80%E6%AD%BB-%E8%BF%9B%E7%A8%8B">查看/杀死 进程</a></li>
<li><a href="#ps-ax-grep-python">ps ax | grep python</a></li>
<li><a href="#dos2unix">dos2unix</a></li>
<li><a href="#%E5%AE%89%E8%A3%85matlab">安装MATLAB</a></li>
<li><a href="#windows-%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5-linux">windows 远程连接 linux</a></li>
<li><a href="#rename">rename</a></li>
<li><a href="#vim">vim</a></li>
<li><a href="#~vimrc">~/.vimrc</a></li>
<li><a href="#%E6%88%91%E7%9A%84~vimrc">我的~/.vimrc</a></li>
<li><a href="#vim%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8">vim自动补全</a></li>
<li><a href="#vim-bundle">vim Bundle</a></li>
<li><a href="#pip">pip</a></li>
<li><a href="#conda">conda</a></li>
<li><a href="#linux%E6%9B%B4%E6%94%B9%E9%BB%98%E8%AE%A4python%E7%89%88%E6%9C%AC">Linux更改默认Python版本</a></li>
<li><a href="#%E6%9F%A5%E7%9C%8B%E7%BD%91%E5%85%B3">查看网关</a></li>
<li><a href="#slurm%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86">slurm集群管理</a></li>
<li><a href="#tmux">tmux</a></li>
<li><a href="#path">$PATH</a></li>
</ul>
</li>
<li><a href="#mac">Mac</a>
<ul>
<li><a href="#%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE">常用快捷键</a></li>
<li><a href="#%E6%96%B0%E5%BB%BA%E6%96%87%E4%BB%B6">新建文件</a></li>
<li><a href="#%E9%9A%90%E8%97%8F%E6%96%87%E4%BB%B6">隐藏文件</a></li>
</ul>
</li>
<li><a href="#markdown">Markdown</a>
<ul>
<li><a href="#markdown-%E8%B6%85%E9%93%BE%E6%8E%A5">Markdown 超链接</a></li>
<li><a href="#markdown-%E7%A9%BA%E6%A0%BC">Markdown 空格</a></li>
<li><a href="#markdown-%E4%BB%A3%E7%A0%81">Markdown 代码</a></li>
<li><a href="#markdown-%E5%85%AC%E5%BC%8F">Markdown 公式</a></li>
<li><a href="#markdown-%E5%9B%BE%E7%89%87">Markdown 图片</a></li>
<li><a href="#markdown-%E7%9B%AE%E5%BD%95">Markdown 目录</a></li>
</ul>
</li>
<li><a href="#latex">LaTex</a>
<ul>
<li><a href="#vscode-%E7%BC%96%E8%AF%91%E5%99%A8">VSCode 编译器</a></li>
<li><a href="#%E4%B8%80%E4%BA%9B%E7%AC%A6%E5%8F%B7%E4%BB%A3%E7%A0%81">一些符号代码</a></li>
</ul>
</li>
<li><a href="#others">Others</a>
<ul>
<li><a href="#paper-writing">paper writing</a>
<ul>
<li><a href="#%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87">插入图片</a></li>
</ul>
</li>
<li><a href="#usb%E5%A4%B1%E6%95%88">USB失效</a></li>
<li><a href="#server-config~202012">server config(~2020.12)</a></li>
</ul>
</li>
</ul>
<!-- /code_chunk_output -->
<hr>
<h1 id="python">Python</h1>
<h2 id="pytorch">Pytorch</h2>
<hr>
<p>连接，返回tensor:</p>
<pre><code>torch.cat(inputs, dimension=0)
</code></pre>
<p>分块：</p>
<pre><code>torch.chunk()
</code></pre>
<hr>
<h3 id="tensor">Tensor</h3>
<p><code>torch.tensor</code>会从data中的数据部分做拷贝（而不是直接引用），根据原始数据类型生成相应的torch.LongTensor、torch.FloatTensor和torch.DoubleTensor
而 <code>torch.Tensor()</code>是python类，更明确地说，是默认张量类型<code>torch.FloatTensor()</code> 的别名，<code>torch.Tensor([1,2])</code>会调用Tensor类的构造函数<code>__init__</code>，生成单精度浮点类型的张量。</p>
<p>会改变tensor的函数操作会用一个下划线后缀来标示。比如，<code>torch.FloatTensor.abs_()</code>会在原地计算绝对值，并返回改变后的tensor，而<code>tensor.FloatTensor.abs()</code>将会在一个新的tensor中计算结果。</p>
<p>若将数据<code>a</code>由<code>torch.DoubleTensor()</code>转化为<code>torch.FloatTensor()</code>，可记为
<code>a.float() 或 a.to(torch.float32)</code>。</p>
<p><img src="https://github.com/PaulTHong/SecretGarden/raw/master/images/torch_Tensor.png" alt="Tensor"></p>
<hr>
<h3 id="item">item()</h3>
<p><code>item()</code>只针对仅含一个元素的张量，取出其值。若为多个元素的张量，可考虑<code>tolist()</code>。</p>
<hr>
<h3 id="torchvisiontransforms">torchvision.transforms</h3>
<ul>
<li>
<p><code>torchvision.transforms.ToTensor()</code>
输入为<code>PIL.Image</code>类型 或<code>numpy.array</code>中的<code>numpy.uint8</code>类型时，才会对其归一化(scale)，即除以255。</p>
</li>
<li>
<p><code>transforms</code>中的一些变换如<code>Resize(), Crop()</code>等输入必为<code>Image</code>型，<code>numpy.array</code>会报错。</p>
</li>
<li>
<p>注：<code>pytorch</code>的图片接口为<code>PIL.Image</code>库，该库读取的图片类型为<code>Image.Image</code>，而<code>cv2</code>读取的图片则与<code>numpy</code>库一致，即<code>numpy.ndarray</code>型。</p>
</li>
</ul>
<hr>
<p>t 代指数据：<br>
cpu转gpu使用<code>t.cuda()</code><br>
gpu转cpu使用<code>t.cpu()</code><br>
tensor转numpy使用<code>t.numpy()</code><br>
numpy转tensor使用<code>torch.from_numpy()</code></p>
<p>cpu,gpu转variable使用<code>Variable(t)</code><br>
Variable转cpu，gpu使用<code>v.data</code><br>
注意：<code>y = Variable(t.cuda())</code>生成一个节点y，<code>y = Variable(t).cuda()</code>，生成两个计算图节点t和y</p>
<p>注：torch 0.4.0及其后续版本合并了Variable与Tensor，故Variable不再使用。
GPU上的Tensor不能直接转为numpy，需先转为CPU上的Tensor再转为numpy。</p>
<hr>
<h3 id="torchvisionsaveimage">torchvision.save_image</h3>
<pre><code>mul(255).add_(0.5).clamp(0, 255).permute(1, 2, 0).to('cpu', torch.uint8)
</code></pre>
<p>对于uint8类型，torch与numpy均为<strong>向下取整</strong>，故先+0.5再clamp。</p>
<pre><code>torch.Tensor: a.to(torch.uint8)
numpy.array: a.astype(np.uint8)
</code></pre>
<hr>
<h3 id="relu">Relu</h3>
<p><code>torch.nn.Relu(inplace=False)</code></p>
<p>inplace为True，将会改变输入的数据 ，否则不会改变原输入，只会产生新的输出。默认为False。</p>
<hr>
<h3 id="nnconvtranspose2d">nn.ConvTranspose2d</h3>
<p>$H_{out} = (H_{in} - 1)\times stride - 2p + dilation\times (k-1) + output_padding + 1$</p>
<p>反卷积即对应上采样过程，HW大小的计算对应卷积计算公式的逆过程。 nn.ConvTranspose2d函数默认参数为：dilation=1, output_padding=0。</p>
<hr>
<h3 id="torchvision">torchvision</h3>
<p><code>toTensor()</code> 中有归一化，且若是二维会扩成三维 <code>[:, :, None]</code> 。
<code>ImageFolder</code> 类中 <code>pil_loader</code>返回时会<code>img.convert('RGB')</code> ; classes 为 [name], class_to_idx 为 {name: idx}, samples 为 [(path, target)] 。</p>
<hr>
<h3 id="cv2%E7%9A%84%E5%9D%91">cv2的坑</h3>
<p>因cv2读取图片为BGR格式，若想将其转为RGB格式后转为tensor,
<code>img = img[:, :, -1]</code> 后使用 <code>torch.from_numpy(img)</code> 会报错。
解决方案一：
<code>img = img[:, :, -1].copy()</code>
解决方案二：
<code>img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</code></p>
<hr>
<h3 id="%E8%B0%83%E8%8A%82%E5%AD%A6%E4%B9%A0%E7%8E%87">调节学习率</h3>
<p>在Pytorch 1.1.0及以后的版本中，应先更新优化器optimizer，再更新学习率，代码框架可如下所示：</p>
<pre><code>scheduler = ...
for epoch in range(100):
	train(...)
	validate(...)
	scheduler.step()
</code></pre>
<p><a href="https://pytorch.org/docs/stable/optim.html?highlight=lr#torch.optim.lr_scheduler.MultiStepLR" title="官方文档">How to adjust Learning Rate</a></p>
<blockquote>
<p>Prior to PyTorch 1.1.0, the learning rate scheduler was expected to be called before the optimizer’s update; 1.1.0 changed this behavior in a BC-breaking way. If you use the learning rate scheduler (calling scheduler.step()) before the optimizer’s update (calling optimizer.step()), this will skip the first value of the learning rate schedule. If you are unable to reproduce results after upgrading to PyTorch 1.1.0, please check if you are calling scheduler.step() at the wrong time.</p>
</blockquote>
<hr>
<h3 id="torchnndataparallel">torch.nn.DataParallel()</h3>
<p>model, optimizer 等均可用DataParallel包裹，即表示用多块GPU训练。（CUDA_VISIBLE_DEVICES=0,1,2 此种方式仍为单卡训练，只是占用多块卡的显存。）</p>
<p>以model为例，其一旦被DataParallel包裹之后，其对应的参数state_dict的keys前会多七个字符，即<code>module.</code>。所以在读写checkpoint时需注意，单卡时不能有<code>module.</code>，所以读取一个多卡训练的checkpoint，中间需加入<code>.module</code>，即由<code>model.state_dict()</code> 变为<code>model.module.state_dict()</code>，其实就相当于把读取的参数字典的keys去掉了前七个字符<code>module.</code>。
当然了，若果存储模型时就选择单卡型，即</p>
<pre><code>torch.save({'model': model.module.state_dict()}, save_path)
</code></pre>
<p>则读取时就不需进行去module的操作。
同理，读取单卡checkpoint进行多卡训练时，按单卡代码定义好model（注意此时从CPU转到GPU上，即末尾加个<code>.cuda()</code>或<code>.to(device)</code>，device需定义一下，可为<code>'cuda'</code>）,optimizer等，最后加一个</p>
<pre><code>model = torch.nn.DataParallel(model)
</code></pre>
<p>即可，此句代码相当于在model的state_dict的keys前加了个<code>module.</code>。</p>
<p>总结:<code>torch.nn.DataParallel()</code>相当于在checkpoint的state_dict()的keys前加上了<code>module.</code>，意味着对应多卡；单卡的state_dict()则无<code>module</code>，<code>model.module.state_dict()</code>则为去掉了<code>module.</code>的state_dict()。</p>
<p>参考：<a href="https://blog.csdn.net/kaixinjiuxing666/article/details/85115077">Missing key(s) in state_dict: Unexpected key(s) in state_dict:</a></p>
<h3 id="torchnndistributeddataparallel">torch.nn.DistributedDataParallel</h3>
<p>这才是真正的分布式训练，且为官方推荐，即使是在单节点多卡上使用时。简单说明一下分布式的常用参数：</p>
<pre class="hljs"><code><div>--dist_url 通信地址，rank为0的进程在这个地址对应的机器上运行。可取为127.0.0.1:8888，8888为任意可用端口，在同一节点上若运行了多个分布式程序，端口需不同，否则会报addres不可用的错误；另IP笔者写为实际IP时程序一直卡着不跑，改为127.0.0.1就好了。
--world_size 进程数量，一般为节点数x每个节点上的GPU数，一个GPU对应一个进程。
--rank 进程的编号，从0开始。因为多进程的重复输出等现象，建议输出日志、存储模型等时调加一句if语句就可以了，如当前rank为0才输出，if rank == 0: 
</div></code></pre>
<p>当用<code>python -m torch.distributed.launch *py</code>训练时，<code>*.py</code>中需要一个args参数为<code>local_rank</code>。</p>
<p>笔者在单节点多卡上进行分布式训练时，习惯用<code>CUDA_VISIBLE_DEVICES=2,3 python *.py</code>的方式来运行，此时程序会找到编号为2，3的两块GPU，且给它们的rank即为0和1。</p>
<p>关于ImageNet等的分布式训练，可参考Github代码: <a href="https://github.com/richardkxu/distributed-pytorch">distributed-pytorch</a></p>
<hr>
<h3 id="numworker">num_worker</h3>
<p><code>torch.utils.data.DataLoader</code>常以batch的方式读取数据，其参数<code>num_worker</code>表示所用核数（并行读取），<code>num_worker=0</code>表示只用一个主进程读取。</p>
<p>在笔者用风格迁移做数据增强的实验中，风格迁移本身需调用一个VGG网络，而分类采用的ResNet50网络。继承了<code>torch.utils.Dataset</code>类，在里面加入了style_transform操作，从而相当于在<code>DataLoader</code>阶段数据就需要放到cuda里。</p>
<p>采取<code>torch.nn.DataParallel</code>单节点多卡训练时，会报错<code>RuntimeError: CUDA error: initialization error</code>，解决办法一只要把<code>num_worker</code>设为0就解决了；但考虑到<code>num_worker=4</code>等可能会提升速度，笔者还是尝试着去解决，在主函数的<code>if __name__ =='__main__':</code>后加入</p>
<pre><code>import multiprocessing as mp
mp.set_start_method('spawn')
</code></pre>
<p>便解决了，意为用多进程读取数据。（注意此时这两行代码必须得写在<code>if __name__ =='__main__':</code>后，不然也可能报错。）</p>
<p>而同样的代码改为<code>torch.nn.DistributedDataParallel</code>版本的分布式单节点多卡训练后，<code>num_worker=0</code>好像也报错了，猜测是分布式本身就是多进程，与只有一个主进程读取数据矛盾。然后改为<code>num_worker=4</code>报了个风格迁移的网络的模型参数weight和输入weight不在一张卡上，稍微修改了下vgg.cuda()和decoder.cuda()在代码中的位置，用了个<code>.to(torch.cuda.current_device())</code>，便解决了，因为分布式下每个进程会使用一块GPU，此时load数据时保证风格迁移网络和数据输入都在这张卡上，就没有问题了。</p>
<hr>
<h3 id="multinomial">multinomial</h3>
<pre><code>torch.multinomial(input, num_samples,replacement=False, out=None) → LongTensor
</code></pre>
<p>按权重张量input的概率采样num_samples次。</p>
<p>参考：<a href="https://blog.csdn.net/monchin/article/details/79787621">torch.multinomial()理解</a></p>
<hr>
<h3 id="loadlua---torchfileload">load_lua -&gt; torchfile.load</h3>
<p>pytorch由0.4版本升级为1.0+版本后，一些函数会发生变化。
对于训好的老式参数模型，读取函数由<code>load_lua</code>变为<code>torchfile.load</code>。
在一次实际操作中，记读取的模型为<code>vgg</code>，则其第一层的权重调用方式由<code>vgg.get(0).weight</code> 变为<code>vgg.modules[0].weight</code>。</p>
<hr>
<h2 id="tensorflow">Tensorflow</h2>
<hr>
<h3 id="tfsession">tf.Session()</h3>
<p><code>sess.run()</code> 返回的不是张量类型，为numpy类型，如<code>np.ndarray</code>, <code>np.float32</code>等。</p>
<p>tensorflow由Session.run()或eval()返回的任何张量都是numpy数组类型。</p>
<pre><code>with tf.Session().as_default() as sess:  
	code A
code B
</code></pre>
<p>加了<code>as_default()</code>后会话结束仍可输出<code>run(), eval()</code>的值，即在code B对应的代码块仍可调用这些函数。</p>
<hr>
<h3 id="tensorflow-%E4%B9%8B-checkpoint">tensorflow 之 checkpoint</h3>
<pre><code>tf.train.get_checkpoint_state(checkpoint_dir,latest_filename=None)
</code></pre>
<p>该函数返回的是checkpoint文件CheckpointState proto类型的内容，其中有model_checkpoint_path和all_model_checkpoint_paths两个属性。其中model_checkpoint_path保存了最新的tensorflow模型文件的文件名，all_model_checkpoint_paths则有未被删除的所有tensorflow模型文件的文件名。</p>
<p>参考：<a href="https://blog.csdn.net/changeforeve/article/details/80268522">https://blog.csdn.net/changeforeve/article/details/80268522</a></p>
<hr>
<h3 id="%E9%80%89%E6%8B%A9gpu">选择GPU</h3>
<ol>
<li>
<p><code>tf.device('/gpu:2')</code><br>
虽然指定了第2块GPU来训练，但是其它几个GPU也还是被占用，只是模型训练的时候，是在第2块GPU上进行。</p>
</li>
<li>
<p><code>os.environ['CUDA_VISIBLE_DEVICES']='2'</code><br>
在训练模型的时候，使用了第2块GPU，并且其它几块GPU也没有被占用，这种就相当于在我们运行程序的时候，将除第2块以外的GPU全部屏蔽了，只有第2块GPU对当前运行的程序是可见的。同样，如果要指定2，3块GPU来训练，则上面的代码中的<code>'2'</code>改成<code>'2, 3'</code>即可。</p>
</li>
<li>
<p><code>CUDA_VISIBLE_DEVICES=2 python train.py</code><br>
在终端中运行命令时选择GPU。</p>
</li>
</ol>
<hr>
<h3 id="tfnn">tf.nn</h3>
<blockquote></blockquote>
<ol>
<li>如果只是想快速了解一下大概，不建议使用<code>tf.nn.conv2d</code>类似的函数，可以使用<code>tf.layers</code>和<code>tf.contrib.layers</code>高级函数。</li>
<li>当有了一定的基础后，如果想在该领域进行深入学习，建议使用<code>tf.nn.conv2d</code>搭建神经网络，此时会帮助你深入理解网络中参数的具体功能与作用，而且对于loss函数需要进行正则化的时候很便于修改，能很清晰地知道修改的地方。而如果采用<code>tf.layers</code>和<code>tf.contrib.layers</code>高级函数，由于函数内部有正则项，不利于深入理解。而且如果编写者想自定义loss，此时比较困难，如果读者想共享参数，计算loss函数中的正则项时，应该只计算一次，如果采用高级函数可能不清楚到底如何计算的。</li>
</ol>
<hr>
<h3 id="%E5%8D%B7%E7%A7%AF%E6%8E%A2%E8%AE%A8">卷积探讨</h3>
<p>输出大小m与输入大小n的关系，其中p表示补丁padding大小，k表示卷积核kernel大小，s表示滑动步长stride：</p>
<p>$$ m = \frac{n + 2*p - k}{s} + 1 $$</p>
<p>那么当不能整除时，各大框架如何处理呢？</p>
<p>先温故一下两大框架的2维卷积函数：</p>
<pre><code>tf.nn.conv2d(input, filter, strides, padding)
</code></pre>
<p>其中input大小为[batch, height, width, channel_in]， filter大小为 [height_kernel, width_kernel, channel_in, channel_out], strides为 [1, stride, stride, 1], padding有'SAME'和'VALID'两个选项。</p>
<pre><code>torch.nn.Conv2d(in_c, out_c, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)
</code></pre>
<p>其中参数一看就明白（论torch的可读性），就不赘述了。</p>
<p><strong>Tensorflow</strong>卷积池化均<strong>向上取整</strong>，简单粗暴。其有'SAME'和'VALID'两种补丁模式：前者超过原图边界处用0填充，当kernel为奇数时，padding可能只补一边；后者确保不超过边界，可能会丢失一些信息。
要保持图片尺寸不变，看一个特例，即常用stride=1，且kernel为奇数，此时只需 k-2p=1 即可。</p>
<p><strong>PyTorch</strong>则<strong>向下取整</strong>。
以Resnet经典一层（[1x1, 3x3, 1x1] + [1x1] shortcut）为例，padding为0输出大小为：
$$m = \lfloor \frac{n-1}{s} + 1 \rfloor $$
当s=1时，大小不变；当s=2时，若输入n为偶数则m为其一半，为奇数则m相当于对n/2向上取整。</p>
<p>当padding只补一边时很有意思，caffe补左上，Tensorflow补右下，Pytorch补一圈（仍要保证大小不变时有待探究）。</p>
<hr>
<h3 id="%E6%84%9F%E5%8F%97%E9%87%8E">感受野</h3>
<p>$$ RF_n = RF_{n-1} + (kernel_size - 1) * stride $$</p>
<p>RF(n): 当前层感受野
RF(n-1): 上一层感受野
kernel_size: 当前层卷积核大小
stride: 之前所有层stride的乘积</p>
<p>特殊: 二维stride=1时，共$l$层，每层kernel大小均为$k$（即$k \times k$），则最后一层像素点感受野为
$$ (k - 1) * l + 1 $$</p>
<hr>
<h3 id="resnet">ResNet</h3>
<p>Bottleneck每个block出去channel 为 planes * expansion, 如 512 * 4 。</p>
<hr>
<h3 id="ncwh">(N,C,W,H)</h3>
<p>tensorflow默认为NHWC，其访存局部性更好；而torch的NCHW为GPU推荐方式。</p>
<h3 id="%E4%BC%98%E5%8C%96%E5%99%A8">优化器</h3>
<p>据说SGD比ADAM稳定。</p>
<h3 id="training-accuracy">training accuracy</h3>
<p>某些情况下全体数据集上的training accuracy显示为100%时不一定为100%，如在采用BatchNormalization模块时，$\mu$和$\sigma$随着batch变化而变化，而训练集上的准确度是以batch为单位来测量的。</p>
<hr>
<h2 id="python">Python</h2>
<hr>
<h3 id="npclip">np.clip()</h3>
<p>上下界截取。</p>
<hr>
<h3 id="nprandomchoice">np.random.choice()</h3>
<p><code>random.choice()</code>函数每次只能选择一个，而<code>np.random.choice()</code>则可选择多个，但需注意一个默认的参数<code>replace=True</code>，表示选取的元素可能重复。</p>
<p>如下代码表示从<code>a</code>中不重复地选取三个元素，<code>a</code>可以是<code>list</code>、<code>np.array</code>等类型，其中每一个元素被选到的比例均记录在参数<code>p</code>中。
<code>np.random.choice(a, 3, replace=False, p=[*])</code></p>
<hr>
<h3 id="%E6%8E%92%E5%BA%8F">排序</h3>
<pre><code>a.sort()   a也变  返回 None
sorted(a)  a不变  返回 变后结果
</code></pre>
<hr>
<h3 id="zip">zip</h3>
<p>python3中 <code>zip()</code> 返回iterator，没有<code>.sort()</code>属性, 可<code>list(zip())</code>再调用<code>sort()</code> 或者 直接<code>sorted(zip())</code>。</p>
<p><code>zip(*a)</code> 解压</p>
<hr>
<h3 id="eval">eval()</h3>
<p><code>eval()</code>函数十分强大，官方demo解释为：将字符串str当成有效的表达式来求值并返回计算结果。<code>exec()</code>功能类似，执行python语句。</p>
<hr>
<h3 id="f-string">f-string</h3>
<pre><code>f&quot;string&quot;
</code></pre>
<p>类似str.format{}接受的格式字符串。
注：Python3.6才开始有。</p>
<p>参考：<a href="https://blog.csdn.net/s740556472/article/details/81111493">python3.6 新特性：f-string PEP 498: Formatted string literals</a></p>
<hr>
<h3 id="glob">glob</h3>
<p><code>glob.glob()</code>函数，里面的通配符匹配，在Windows下是不区分大小写的，而在Linux下是区分大小写的。</p>
<p>故比如在Windows中读取图片时，*.jpg和*.JPG若都放在形参里，则会读取两次，注意。</p>
<p>另需注意<code>glob.glob()</code>搜索时需有分隔符，即 \ 或 / ，不然搜索结果为空。</p>
<p>推荐写法：</p>
<pre><code>impot glob 
import os
imgs = glob.glob(os.path.join(img_path, '*.jpg'))
for img in imgs:
	print(os.path.split(img)[-1])
</code></pre>
<p>总结：<code>glob.glob</code>的参数是一个只含有方括号、问号、正斜线的正则表达式，同时也是shell命令。</p>
<hr>
<h3 id="ospathdirnamefile">os.path.dirname(__file__)</h3>
<p>在脚本test.py里写入<code>print(os.path.dirname(__file__))</code>。</p>
<ul>
<li>当脚本是以完整路径被运行的， 那么将输出该脚本所在的完整路径，比如：<pre class="hljs"><code><div>python d:/pythonSrc/test/test.py
输出: d:/pythonSrc/test
</div></code></pre>
</li>
<li>当脚本是以相对路径被运行的， 那么将输出空目录，比如：<pre class="hljs"><code><div>python test.py
输出: 空字符串
</div></code></pre>
</li>
</ul>
<h3 id="argparse">argparse</h3>
<pre><code>import argparse
parser = argparse.ArgumentParser()
parser.add_argument('-n', '--name')
args = parser.parse_args()
</code></pre>
<p>当 <code>-n</code> 和 <code>--name</code> 同时存在时，默认采用后者。命令行中输入二者均可（如 <code>python test.py -n ht</code>），代码中调用时用全称即 <code>args.name</code>。</p>
<h4 id="bool%E5%9E%8Bargparse-%E5%9D%91">bool型argparse 坑</h4>
<p>在使用argparse时发现无法传递bool型变量，无论命令行输入True还是False，解析出来之后都是True。因为输入首先均作为str类型处理。</p>
<p>出错版本：代码<code>test.py</code>中</p>
<pre><code>parser.add_argument('--trained', type=bool, default=False)
</code></pre>
<p>解决办法1：
注册自定义回调函数：</p>
<pre><code>def str2bool(v):
	if v.lower() in ('yes', 'true', 't', 'y', '1'):
		return True
	elif v.lower() in ('no', 'false', 'f', 'n', '0'):
		return False
	else:
		raise argparse.ArgumentTypeError('Unsupported value encountered.')
</code></pre>
<p>从而将type由bool改为str2bool即可：</p>
<pre><code>parser.add_argument('--trained', type=str2bool, default=False)
</code></pre>
<p>解决办法2：
将bool型变为str型：</p>
<pre><code>parser.add_argument('--trained', type=str, default='False')
</code></pre>
<p>在主函数中对应判断稍加修改：</p>
<pre><code>if args.trained == 'False':
	code1
elif args.trained == 'True'
	code2
</code></pre>
<p>解决办法3：(推荐!!!)<br>
argparse有参数action, 取值有两种：</p>
<pre><code>action='store_true'
action='store_false'
</code></pre>
<p>此时运行代码的命令行只需要参数名 <code>--trained</code> 即可，其后不需输入具体参数。</p>
<p><code>action='store_true'</code>意味着<code>trained</code>取值默认为<code>False</code>。即<code>python test.py</code>时<code>trained</code>取值为<code>False</code>；而<code>python test.py --trained</code>时<code>trained</code>取值变为<code>True</code>。
若<code>argparse()</code>中添加<code>default</code>, 则<code>trained</code>默认取值与<code>default</code>值相同。<br>
<code>action='store_true'</code>分析同理。</p>
<p>参考：<a href="https://stackoverflow.com/questions/15008758/parsing-boolean-values-with-argparse">https://stackoverflow.com/questions/15008758/parsing-boolean-values-with-argparse</a></p>
<hr>
<h3 id="class">class</h3>
<p>class里面有多个类的属性时，如多个全连接层fc1, fc2, fc3：</p>
<ol>
<li>
<p>采用setattr 和getattr</p>
<pre><code> setattr(‘fc%i’, i) 
</code></pre>
</li>
<li>
<p>直接self里构造一个list</p>
</li>
</ol>
<hr>
<h3 id="call">__call__()</h3>
<blockquote>
<p>所有的函数都是可调用对象。</p>
</blockquote>
<blockquote>
<p>一个类实例也可以变成一个可调用对象，只需要实现一个特殊方法<code>__call__()</code></p>
</blockquote>
<hr>
<h3 id="dir">__dir__()</h3>
<p>取类的属性，如<code>a.__dir__()</code>，<code>a</code>表示一个类的对象。</p>
<hr>
<h3 id="python%E5%87%BD%E6%95%B0%E4%BC%A0%E5%AF%B9%E8%B1%A1call-by-object">Python函数——传对象(call by object)</h3>
<blockquote>
<p>结论：Python不允许程序员选择采用传值还是传引用。Python参数传递采用的肯定是“传对象引用”的方式。这种方式相当于传值和传引用的一种综合。如果函数收到的是一个<strong>可变对象</strong>（比如字典或者列表）的引用，就能修改对象的原始值－－相当于通过“<strong>传引用</strong>”来传递对象。如果函数收到的是一个<strong>不可变对象</strong>（比如数字、字符或者元组）的引用，就不能直接修改原始对象－－相当于通过“<strong>传值</strong>'来传递对象。</p>
</blockquote>
<p>测试：numpy数组也是“传引用”，不想传引用时可采用：</p>
<pre><code>import copy
def temp(A):
	x = copy.copy(A)
	………
</code></pre>
<p>注意对于list等涉及两个维度时可能需采用<code>copy.deepcopy()</code>.</p>
<p>举例：</p>
<pre><code>a = [[1, 2], [3, 4], 5]
print(a)

b = a.copy()
print(b)

b[0][0] = 9999
print(b)
print(a)

c = a.copy()
print(c)
c[2] = 8888
print(c)
print(a)
</code></pre>
<p>输出为：</p>
<pre><code>[[1, 2], [3, 4], 5]
[[1, 2], [3, 4], 5]
[[9999, 2], [3, 4], 5]
[[9999, 2], [3, 4], 5]
[[9999, 2], [3, 4], 5]
[[9999, 2], [3, 4], 8888]
[[9999, 2], [3, 4], 5]
</code></pre>
<hr>
<h3 id="globals">globals()</h3>
<p>该函数会以字典类型返回当前位置的全部全局变量。</p>
<hr>
<h3 id="zfill">zfill</h3>
<pre><code>str.zfill(n)
</code></pre>
<p>字符串前面补0 至n位(str指代字符串)。</p>
<hr>
<h3 id="ravel--flatten">ravel() &amp; flatten()</h3>
<p><code>a.ravel()</code>和<code>a.flatten()</code>效果一样。
但前者是产生视图，令<code>b=a.ravel()</code> ，b变a也变，<code>flatten</code>则不变。<br>
但</p>
<pre><code>b = a.ravel()
b is a    输出：False  
c = a.flatten()  
c is a    输出：False
</code></pre>
<hr>
<h3 id="nprollaxis">np.rollaxis（）</h3>
<p>改变维度顺序。</p>
<pre><code>np.rollaxis(a, n1, n2) 
</code></pre>
<p>a是一个数组，将第n2个维度移到n1维度前。
常见于图片张量中，比如C x H x W  通过np.rollaxis(a, 2, 1)变为C x W x H 。</p>
<p>测试样例：</p>
<pre><code>import numpy as np
a = np.arange(24).reshape(2, 3, 4)

print(a, '\n')

print(np.rollaxis(a, 2), '\n')

print(np.rollaxis(a, 2, 1), '\n')

print(np.rollaxis(a, 1, 0), '\n')

print(np.rollaxis(a, 1, 2), '\n')
</code></pre>
<p>输出：</p>
<pre><code>[[[ 0  1  2  3]
  [ 4  5  6  7]
  [ 8  9 10 11]]

 [[12 13 14 15]
  [16 17 18 19]
  [20 21 22 23]]] 


[[[ 0  4  8]
  [12 16 20]]

 [[ 1  5  9]
  [13 17 21]]

 [[ 2  6 10]
  [14 18 22]]

 [[ 3  7 11]
  [15 19 23]]] 


[[[ 0  4  8]
  [ 1  5  9]
  [ 2  6 10]
  [ 3  7 11]]

 [[12 16 20]
  [13 17 21]
  [14 18 22]
  [15 19 23]]] 


[[[ 0  1  2  3]
  [12 13 14 15]]

 [[ 4  5  6  7]
  [16 17 18 19]]

 [[ 8  9 10 11]
  [20 21 22 23]]] 


[[[ 0  1  2  3]
  [ 4  5  6  7]
  [ 8  9 10 11]]

 [[12 13 14 15]
  [16 17 18 19]
  [20 21 22 23]]]
</code></pre>
<hr>
<h3 id="matplotlib">matplotlib</h3>
<p>matplotlib在终端中不能显示图（通过ssh等连接Linux服务器）</p>
<pre><code>import matplotlib as mpl
mpl.use('Agg')
import mpl.pyplot as plt
</code></pre>
<p>注：前两句必须在第三句前面。</p>
<p>matplotlib经常用在python shell中用作交互式编程，也有将其作为类似wxpython和pygtk这样的图形化界面使用，也有将其用在网络应用服务器中动态提供图片。因此为了能够包含所有的这些需求，matplotlib提供了指向不同输出的后端，相对应的前端就是用户编写使用的代码接口。后端包含两类，一类是user interface backends（用于pygtk, wxpython, tkinter, qt4, or macosx这类的交互式后端），另一类则是hardcopy backends（主要用于PNG, SVG, PDF, PS这类图片渲染并保存）。<br>
<strong>Agg</strong>是一个非交互式后端，这意味着它不会显示在屏幕上，只保存到文件。</p>
<hr>
<h3 id="pltplot">plt.plot()</h3>
<p><code>from matplotlib import pyplot as plt</code></p>
<ul>
<li><strong>保存图片</strong>
<code>plt.savefig()</code>函数第一个参数为保存路径，如*.png，但png等格式图片清晰度有损，而存为*.svg为无损格式，svg格式可通过浏览器打开。另一个参数为<code>dpi</code>，其值越大图片的分辨率越高，<code>dpi=500</code>在一定程度上已经很清晰了。</li>
<li><strong>调节坐标轴刻度</strong>
基础些的为<code>xticks，yticks</code>，<code>xticks(position, label, rotation)</code>表示在position位置标注label，这两个一般为List型，rotation控制标注的旋转。
而进阶一点则可借助<code>MultipleLocator</code>，其后的参数表示刻度间距，而对应的在<code>xlim, ylim</code>取值错开一点可使第一个标注点不在原点。
如下例所示：<pre class="hljs"><code><div>from matplotlib.pyplot import MultipleLocator
...
plt.xticks(range(2, 21, 2), list(range(2, 21, 2)))
ax = plt.gca()
y_major_locator = MultipleLocator(2)
ax.yaxis.set_major_locator(y_major_locator)
plt.ylim(57.5, 76.5)
...
</div></code></pre>
<img src="https://github.com/PaulTHong/SecretGarden/raw/master/images/plot_tick.png" alt="Plot_tick"></li>
</ul>
<hr>
<h2 id="opencv2">opencv2</h2>
<hr>
<h3 id="resize">resize</h3>
<p>先宽再高！</p>
<hr>
<p>cv2读取图片默认为BGR模式，且<code>imshow</code>, <code>imwrite</code>也都对应BGR模式！<br>
<strong>BGR-&gt;RGB</strong>:</p>
<pre><code>img_rgb = img[:, :, ::-1]  
</code></pre>
<p>或</p>
<pre><code>b, g, r = cv2.split(img)  
img_rgb = cv2.merge([r, g, b])  
</code></pre>
<p>或</p>
<pre><code>img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
</code></pre>
<p>注意Image包(<code>from PIL import Image</code>)读取图片时会取该图片的实际通道数，而.png等类型图片会有4个通道，即除R、G、B三个外还有一个透明度A, 以R为例，此时计算公式为：$R = \alpha * R + (1-\alpha) * A $， $\alpha=1 $时即对应RGB。故若Image读取此类图只想得到RGB三通道，需</p>
<pre><code>Image.open(img_path).convert('RGB')
</code></pre>
<p>而cv2的 <code>imread</code> 函数读取方式参数有 <code>cv2.IMREAD_COLOR, cv2.IMREAD_UNCHANGED, cv2.IMREAD_GRAYSCALE</code> 等，默认即为 <code>cv2.IMREAD_COLOR</code>，会自动得到三通道图。</p>
<hr>
<p>像素取值为0~255时， <code>cv2.imshow()</code>函数的参数矩阵元素必须为整数，一般取<code>np.uint8</code>型。
但<code>cv2.imwrite()</code>存图时参数可以不为整数，相反取整之后可能存在一定的色彩失真（若肉眼能观察到）。</p>
<hr>
<h1 id="matlab">MATLAB</h1>
<h3 id="matlab-bsxfun">MATLAB bsxfun</h3>
<p>对两个矩阵A和B之间的每一个元素进行指定的计算（函数fun指定）；并且具有自动扩维的作用。</p>
<p>例如：</p>
<pre><code>J=bsxfun(@minus,im,A); 
J=bsxfun(@rdivide,J,F4);
J=bsxfun(@plus,J,A);
</code></pre>
<p>参考：<a href="https://www.mathworks.com/help/matlab/ref/bsxfun.html;jsessionid=0d28b1fcafdfc9f78279a63a7d26" title="MATLAB bsxfun">MATLAB bfxfun</a></p>
<hr>
<h2 id="python-%E4%B8%8E-matlab%E7%9A%84%E4%B8%80%E4%BA%9B%E5%87%BD%E6%95%B0%E5%8C%BA%E5%88%AB%E7%BB%86%E8%8A%82">Python 与 MATLAB的一些函数区别（细节）</h2>
<p>Python中的matrix类型对象加个 <strong>.A</strong> 可变为np.array型对象。</p>
<p>MATLAB 　 <strong>A\b</strong> 即求解Ax=b时的x, 当A不是方阵时仍可求解, 所以比inv(A)*b要强大些；Python中A\b不是方阵时则不行，可采用最小二乘思想求解，如求A' A x = A' b。</p>
<p><strong>spdiags</strong>函数 　Python中位于scipy.sparse中，当形参为spdiags(A, d, m, n)时，Python和MATLAB中的A为<strong>转置</strong>关系。</p>
<p><strong>svd</strong>分解　 Python中位于np.linalg中，<strong>U, S, V = svd(A)</strong></p>
<p>如A为3x5矩阵，则MATLAB中结果为：U: 3x3 S: 3x5  V:5x5， S为只有主对角元素非零的矩阵
Python中U V一致，S为一向量。两种S可通过diag命令互相转化。
对于svd的其他参数，MATLAB的svd(A, <strong>'econ'</strong>)对应Python中的svd(A, <strong>full_matrices=False</strong>)，注意此时前者返回的U S V维度分别为3x3 3x3 5x3，后者则为3x3 1x3 3x5，即除了S不同外，V又为转置关系。</p>
<hr>
<h3 id="%E5%A4%8D%E6%95%B0%E5%9F%9F">复数域</h3>
<p>MATLAB一个复数矩阵(向量也为矩阵)记为A，则  <strong>A'</strong> 表示A的共轭再转置，而 <strong>A.'</strong> 才表示A的转置，<code>conj(A)</code> 表示A的共轭。</p>
<p>Python中则<strong>A.T</strong>表示A的转置，<code>A.conjugate()</code>或者<code>np.conjugate(A)</code>表示A的共轭。</p>
<p>所以，当翻译MATLAB代码为Python时，若为复数域上的矩阵，MATLAB中出现A'时，Python务必对应为 <strong>A.conjugate().T</strong>。</p>
<p>另python中有个<code>np.vdot()</code>函数，np.vdot(a, b)中两个形参都必须为向量（1xn,nx1矩阵也可），但a、b不管是行还是列向量表示都不影响。np.vdot(a, b)表示a先取共轭再与b做内积（即点乘求和），故返回值为一个数值。（而np.dot(a, b)时，若a为1xn，b为nx1，返回值为1x1矩阵，即[[ value ]]。）</p>
<hr>
<h1 id="linux">Linux</h1>
<h3 id="bash">bash</h3>
<p>推荐bash，比sh更强大。
shell开头写</p>
<pre><code>#!/bin/bash
</code></pre>
<hr>
<h3 id="adduser-useradd">adduser useradd</h3>
<p>adduser 较为便捷</p>
<p>另useradd也可，如</p>
<pre><code>useradd -d /home/hongt -s /bin/bash -m hongt
</code></pre>
<hr>
<h3 id="ls">ls</h3>
<p>ls隐藏pyc文件，可写在<code>~/.bashrc</code>中：</p>
<pre><code>alias ls='ls -I*.pyc'
</code></pre>
<p>注：第一个<code>ls</code>可任意命名。</p>
<hr>
<h3 id="%E8%BD%AF%E9%93%BE%E6%8E%A5">软链接</h3>
<p><code>ln -s 原链接路径 软链接路径 </code></p>
<p>在链接路径有多层嵌套时，建议采用绝对路径避免出错。</p>
<hr>
<h3 id="ssh">ssh</h3>
<p>图形界面：</p>
<pre><code>ssh -X user_name@user_IP
</code></pre>
<hr>
<h3 id="%E6%9F%A5%E7%9C%8Bcpu-gpu%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5">查看CPU GPU使用情况</h3>
<p>查看GPU</p>
<pre><code>nvidia-smi
</code></pre>
<p>动态查看GPU，时间间隔为0.5</p>
<pre><code>watch -n 0.5 nvidia-smi
</code></pre>
<p>查看CPU（按<code>q</code>退出）</p>
<pre><code>top
</code></pre>
<p>查看显卡cuda版本</p>
<pre><code>cat /usr/local/cuda/version.txt
</code></pre>
<hr>
<h3 id="%E8%BE%93%E5%87%BA%E6%9C%BA%E5%88%B6">输出机制</h3>
<p>stdout和stderr两种模式，对应编号分别为1和2。
<code>[cmd] &gt;[filename]</code> 表示将输出直接写入filename，但若报错仍打印在终端屏幕。
要使错误也写入文件，不打印在终端，末尾加个<code>2&gt;&amp;1</code>即可，即</p>
<pre><code>[cmd] &gt;[filename] 2&gt;&amp;1  
</code></pre>
<p>若既想把输出打印在终端，又写入文件，则借助<code>tee</code>：</p>
<pre><code>[cmd] |tee [file]
</code></pre>
<p>注意<code>tee</code>不能写入错误，且发现运行python命令时调到<code>schedule</code>库时，并未在终端打印信息。
此时加个<code>-u</code>即可解决! 默认输出会优先输出stderr，因其不需缓存，而<code>python -u</code>则意味着完全按照程序顺序输出。
(将python执行脚本输出到屏幕结果直接重定向到日志文件的情况下，使用-u参数，这样将标准输出的结果不经缓存直接输出到日志文件。)</p>
<p><strong>·</strong> 上述写入文件命令均为覆盖性写入，若想在尾部追加写入，则对应修改为：把<code>&gt;</code>改为<code>&gt;&gt;</code>； <code>tee</code> 后加入 <code>-a</code>。即：</p>
<pre><code>[cmd] &gt;&gt;[filename] 2&gt;&amp;1  
[cmd] |tee -a [file]
</code></pre>
<p>推荐eg.:</p>
<pre><code>python -u train.py |tee train.log
</code></pre>
<p>注：
命令行结尾有<code>&amp;</code>相当于并行，即在一个终端窗口里各命令可以同时运行，运行了一行命令后可以继续输入。
而没有<code>&amp;</code>相当于串行，按顺序执行命令，前一命令运行结束后才会运行下一条命令，但前提是前一命令能正常运行，不会报错。</p>
<hr>
<h3 id="export--echo">export &amp; echo</h3>
<p>linux环境下每次新打开一个窗口都会预执行<code>~/.bashrc</code>。
<code>export</code> 给变量赋值， <code>echo</code> 查看变量值。</p>
<p>但注意变量生效区域：
case1:
tmux环境下，左边窗口export, 右边窗口echo为空。
case2:
在当前窗口中新建一个脚本ht.sh，vim ht.sh, 在其中export, 关掉脚本并 bash ht.sh后， echo也为空。
若export写进~/.bashrc, 则一直生效。
case3:
在当前窗口export, 然后vim ht.sh，在里面echo有值。</p>
<p>发散：<strong>配置CUDA环境</strong>
应在主函数开头便写好 <code>export CUDA_HOME=...</code> 等；
若想一直生效，写进<code>~/.bashrc</code>即可。</p>
<hr>
<h3 id="tar">tar</h3>
<pre><code>-c: create, 建立压缩档案
-x：解压
-z，-j：分别表示以gzip和bzip2格式压缩解压
-v: 显示解压或压缩过程
-C：指定目录，需提前创建
-t：查看内容
-r：向压缩归档文件末尾追加文件
-u：更新原压缩包中的文件
-f: (必需参数)使用档案名字，该参数是最后一个参数，后面只能接档案名。
</code></pre>
<p>解压：</p>
<pre><code>tar –xvf file.tar //解压 tar包

tar -xzvf file.tar.gz //解压tar.gz

tar -xjvf file.tar.bz2 //解压 tar.bz2

tar –xZvf file.tar.Z //解压tar.Z

unrar e file.rar //解压rar

unzip file.zip //解压zip方式1

tar -zcvf *.zip // 解压zip方式2
</code></pre>
<p>压缩:</p>
<pre><code>tar –cvf jpg.tar *.jpg //将目录里所有jpg文件打包成jpg.tar

tar –czf jpg.tar.gz *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz

tar –cjf jpg.tar.bz2 *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2

tar –cZf jpg.tar.Z *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z

rar a jpg.rar *.jpg //rar格式的压缩，需要先下载rar for linux

zip jpg.zip *.jpg //zip格式的压缩，需要先下载zip for linux
</code></pre>
<p>注：若压缩时想排除一些文件或文件夹，可借助<code>--exclude</code>参数，排除多个文件(夹)时则使用多次<code>--exclude</code>，另排除的文件夹最后不要加<code>/</code>。例如：
<code>tar -czvf ht.tar.gz images --exclude=1.png --exclude=images/monkey</code></p>
<hr>
<h3 id="scp">scp</h3>
<p><code>-P</code>指定端口，<code>-v</code>输出日志信息。</p>
<p>文件数过多等情况下，可能未完全复制，先设置超时时间为无穷大即可。</p>
<pre><code>set timeout=-1
</code></pre>
<p>But failed!</p>
<p>建议先打包(压缩)再复制。</p>
<h3 id="ctrl%E7%B1%BB%E5%BF%AB%E6%8D%B7%E9%94%AE">Ctrl类快捷键</h3>
<p><code>Ctrl+A</code>: 光标移到行首。
<code>Ctrl+E</code>: 光标移到行尾。
<code>Ctrl+S</code>：冻结窗口。注意：这不是保存的命令。当屏幕输出过快时，用户可冻结窗口来查看瞬时的输出。
<code>Ctrl+Q</code>：取消冻结窗口。</p>
<h3 id="%E6%9F%A5%E7%9C%8B%E4%BD%8D%E7%BD%AE">查看位置</h3>
<p>查看安装应用的位置，如Python, ls（package代，下同）等：</p>
<pre><code>which package
</code></pre>
<p>查看Python中安装的库的位置，如numpy,torch等，可通过pip:</p>
<pre><code>pip show package
</code></pre>
<hr>
<h3 id="linux%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E5%A4%A7%E5%B0%8F%E6%95%B0%E9%87%8F">Linux查看文件大小数量</h3>
<p>当前文件夹总大小</p>
<pre><code>du -sh 
</code></pre>
<p>当前文件夹下各文件大小</p>
<pre><code>du -sh *
</code></pre>
<p>当前文件夹下 文件+子目录 个数：</p>
<pre><code>ls -l |wc -l
</code></pre>
<p>当前文件夹下 文件 数目</p>
<pre><code>ls -l |grep ^-|wc -l
</code></pre>
<p>可在<code>~/.bashrc</code>中 <code>alias</code> 该命令， 比如别称为cal_num，输入简洁。</p>
<hr>
<h3 id="linux-%E6%9F%A5%E7%9C%8B%E7%A1%AC%E7%9B%98%E5%88%86%E5%8C%BA%E5%86%85%E5%AD%98">Linux 查看硬盘分区内存</h3>
<pre><code>df -hl
lsblk
</code></pre>
<p><code>lsblk</code>命令用于列出所有可用块设备的信息，而且还能显示他们之间的依赖关系，但是它不会列出RAM盘的信。</p>
<h3 id="%E6%9F%A5%E7%9C%8B%E6%9D%80%E6%AD%BB-%E8%BF%9B%E7%A8%8B">查看/杀死 进程</h3>
<p>查看进程：</p>
<pre><code>ps -ef |grep [process-name]
</code></pre>
<p>杀死进程：</p>
<pre><code>kill -9 [process-number]
</code></pre>
<hr>
<h3 id="ps-ax--grep-python">ps ax | grep python</h3>
<p>查看其他人在运行的代码。</p>
<hr>
<p>在服务器上某目录下输入：</p>
<pre><code>python -m http.server  
</code></pre>
<p>再在自己电脑浏览器中输入 服务器IP:8000 即可访问该目录。</p>
<hr>
<h3 id="dos2unix">dos2unix</h3>
<p>因格式原因，有时候文件从windows复制到linux系统后执行会报错，比如代码文件中的回车空格等问题。先执行一句 <code>dos2unix(filename)</code> 即可.</p>
<hr>
<h3 id="%E5%AE%89%E8%A3%85matlab">安装MATLAB</h3>
<p>刚安装好时只能在MATLAB的安装路径内运行，即在<code>……/bin</code>内输入<code>./matlab</code>。要使在终端的任意路径下都可运行MTALAB，在<code>/usr/local/bin</code>里绑定一个软链接即可，即</p>
<pre class="hljs"><code><div>cd /usr/local/bin
sudo ln -s ……/bin/matlab matlab
</div></code></pre>
<p>此时在终端任意路径下输入<code>matlab</code>都可运行了。</p>
<hr>
<h3 id="windows-%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5-linux">windows 远程连接 linux</h3>
<p><strong>linux</strong>上安装<strong>xrdp</strong></p>
<p>注意第一次连接到某个用户前该用户需在linux上运行：</p>
<pre><code>echo &quot;xfce4-session&quot; &gt;~/.xsession
</code></pre>
<p>然后（此步似乎也可以跳过）</p>
<pre><code>sudo service xrdp restart
</code></pre>
<p><strong>windows</strong>上按“win+R”后输入<strong>mstsc</strong>，输入对应的IP、用户名、密码即可。</p>
<p>参考：<a href="https://blog.csdn.net/woodcorpse/article/details/80503232">Windows10远程桌面Ubuntu16.04</a></p>
<p><a href="https://blog.csdn.net/u011054333/article/details/79905102">Linux和Windows间的远程桌面访问</a></p>
<hr>
<h3 id="rename">rename</h3>
<p>将文件*中的from重命名为to:</p>
<pre><code>rename 's/from/to/' *
</code></pre>
<hr>
<h3 id="vim">vim</h3>
<p>三种模式名字：命令行模式，插入模式，末行模式</p>
<p>命令行模式中输入<code>:u</code>或<code>:undo</code>表示撤销。（注：命令行模式下输入<code>:</code>即进入了末行模式。）</p>
<p>查找函数定义处等: 命令行模式下输入 <code>;jd</code></p>
<p>搜索：命令行模式下输入 <code>/usr</code> （usr为待搜索字符串，回车即到该字符串处）<br>
<code>n</code> 查看下一个匹配； <code>N</code> 上一个</p>
<p>命令行模式下：</p>
<pre><code>v  按字符复制  
V  按行复制  
Ctrl+V  按块复制
</code></pre>
<p>使用<code>v</code>命令进入visual模式后：</p>
<pre><code>d  剪切
y  复制
p  粘贴
^  选中当前行，光标位置到行首（或者使用键盘的HOME键）
$  选中当前行，光标位置到行尾（或者使用键盘的END键）
</code></pre>
<p>使用<code>Ctrl+V</code>进入块模式后，可以进行多列的同时修改（比如多行注释，python中为插入#），修改方法是：<br>
选中多列，按键<code>Shift+i</code>进行块模式下的插入, 输入字符之后，按键<code>ESC</code>，完成多行的插入。</p>
<hr>
<p>设置自动缩进后，整段复制时下一句会比上一句多个Tab,解决办法：<br>
复制前在末行模式输入：<code>set paste</code><br>
取消则：<code>set nopaste</code></p>
<p>替换文字:<br>
在末行模式输入: <code>{作用范围}s/{目标}/{替换}/{替换标志}</code>
例如:<code>%s/foo/bar/g</code>会在全局范围(%)查找foo并替换为bar，所有出现都会被替换（g）。</p>
<hr>
<h3 id="vimrc">~/.vimrc</h3>
<pre><code>变量名          缩写                       含义
tabstop=X       ts          编辑时一个TAB字符占多少个空格的位置。 
(no)expandtab   (no)et      是否将输入的TAB自动展开成空格。开启后要输入TAB，需要Ctrl-V&lt;TAB&gt; 
(no)smartindent si          基于autoindent的一些改进(原版本为autoindent)

shiftwidth=X    sw          使用每层缩进的空格数。 
softtabstop=X   sts         方便在开启了et后使用退格（backspace）键，每次退格将删除X个空格 
</code></pre>
<p>在Vim中还可以进行自动缩进，主要有<strong>cindent</strong>、<strong>smartindent</strong>和<strong>autoindent</strong>三种。</p>
<p>cindent Vim可以很好的识别出C和Java等结构化程序设计语言，并且能用C语言的缩进格式来处理程序的缩进结构。可以使用以下命令，启用cindent缩进结构：</p>
<pre><code>:set cindent
</code></pre>
<p>smartindent 在这种缩进模式中，每一行都和前一行有相同的缩进量，同时这种缩进形式能正确的识别出花括号，当遇到右花括号<code>}</code>，则取消缩进形式。此外还增加了识别C语言关键字的功能。如果一行是以#开头的，那么这种格式将会被特殊对待而不采用缩进格式。可以使用以下命令，启用smartindent缩进结构：</p>
<pre><code>:set smartindent
</code></pre>
<p>autoindent 在这种缩进形式中，新增加的行和前一行使用相同的缩进形式。可以使用以下命令，启用autoindent缩进形式。</p>
<pre><code>:set autoindent
</code></pre>
<p>参考：<a href="https://blog.csdn.net/luojj26/article/details/50935921">VIM学习笔记 缩进 (Indent)</a></p>
<hr>
<h3 id="%E6%88%91%E7%9A%84vimrc">我的~/.vimrc</h3>
<pre><code>set ts=4
set expandtab
set autoindent
</code></pre>
<p>使vim在三种模式下光标不一样：</p>
<pre><code>if exists('$TMUX')
  let &amp;t_SI = &quot;\&lt;Esc&gt;Ptmux;\&lt;Esc&gt;\&lt;Esc&gt;]50;CursorShape=1\x7\&lt;Esc&gt;\\&quot;
  let &amp;t_EI = &quot;\&lt;Esc&gt;Ptmux;\&lt;Esc&gt;\&lt;Esc&gt;]50;CursorShape=0\x7\&lt;Esc&gt;\\&quot;
else
  let &amp;t_SI = &quot;\&lt;Esc&gt;]50;CursorShape=1\x7&quot;
  let &amp;t_EI = &quot;\&lt;Esc&gt;]50;CursorShape=0\x7&quot;
endif
</code></pre>
<hr>
<h3 id="vim%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8">vim自动补全</h3>
<p>候选框挥之不去，很烦！</p>
<pre><code>Ctrl+Y
</code></pre>
<p>表示退出下拉窗口，并接受当前选项。</p>
<p>其他：</p>
<pre><code>Ctrl + P：向前切换成员
Ctrl + N：向后切换成员
Ctrl + E：退出下拉窗口，并退回原来录入的文字
</code></pre>
<p>参考：<a href="https://blog.csdn.net/henpat/article/details/42077561">vim中自动补全的快捷键</a></p>
<hr>
<h3 id="vim-bundle">vim Bundle</h3>
<p>插件管理：
<strong>·</strong> 第一步：安装vundle</p>
<pre><code>git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim
</code></pre>
<p><strong>·</strong> YouCompleteMe安装完成时，即在vim末行运行<code>:PluginInstall</code>后，需进入其文件夹下运行：</p>
<pre><code>./install.py
</code></pre>
<p>注：此时需要已经安装cmake；YCM文件夹里的第三方库里有谷歌的成分，笔者有一段时间下载不了。(发挥聪明才智，把以前编译好的YCM文件夹直接拷过去就好了)</p>
<p><strong>·</strong> 清除不要的插件，在 .vimrc 中注释掉对应行后，在末行模式运行：</p>
<pre><code>BundleClean
</code></pre>
<hr>
<h3 id="pip">pip</h3>
<p>从清华镜像源更新gpu版本tensorflow</p>
<pre><code>pip install -i https://pypi.tuna.tsinghua.edu.cn/simple/ --upgrade tensorflow-gpu
</code></pre>
<p>清华镜像网站设为默认网站</p>
<pre><code>pip install pip -U
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
</code></pre>
<hr>
<h3 id="conda">conda</h3>
<pre><code>conda create –n python3 python=3.5  (python3为自定义name，下同；3.5为指定python版本)	
conda activate python3
conda deactivate

conda install –n python3 package  (package代指库，如tensorflow)
conda remove –n python3 package  (全删则package改为--all)

conda env list  查看所有配置环境，等价于 conda info --envs
conda list –n python3  查看名为python3环境下所有库
conda search package

conda install -c spyder-ide spyder=3.0.0  指定包的来源(以spyder为例)
（加一个-c表示从http://anaconda.org下载资源包）
例：
conda install -c cjj3779 tensorflow-gpu
conda install -c conda-forge opencv
conda install --channel https://conda.anaconda.org/menpo opencv3	

conda install numpy=1.12.1

conda info tensorflow-gpu=1.2.1
</code></pre>
<p><code>-c</code> 与 <code>--channel</code> 为同一内容的两种表达形式
如安装bottleneck时在anaconda官网搜到一个源头为pandas/bottleneck, 则 <code>--channel https://anaconda.org/pandas</code> 等价于 <code>-c pandas</code></p>
<pre><code>添加清华镜像网站：
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
搜索时显示通道地址：
conda config --set show_channel_urls yes
恢复默认源：
conda config --remove-key channels
显示库源信息：
conda config --show channels
显示所有config:
conda config --show

没有直接重命名，so间接方式：
conda create --name [newname] --clone [oldname]

一次实际配置时记录：
安装Pytorch:
conda install pytorch=0.4.1 cuda80 -c pytorch
conda install torchvision=0.2.1 cuda80 -c pytorch
安装opencv:
conda install opencv -c anaconda
(笔者所装为3.4.2版本，hdf5库版本不匹配，所以需先卸载hdf5:
conda remove hdf5)
</code></pre>
<blockquote>
<p>pip与conda关系：<br>
pip是python自带的，而conda是安装anaconda或者miniconda提供的，俗称的蟒蛇软件商给的，conda可以用来安装管理python，pip当然不能管理python，pip是python下的，所以用pip来装python不可能，conda却可以装python。<br>
有的人不用conda去管理python环境，他们自己安装自己要的python各个版本，然后通过修改全局变量来实验使用哪个版本。（全局变量就是比如你在某路径中输入python，要使可以运行在其他路径下的python.exe，那么这个python.exe就必须为全局变量。）<br>
通过conda安装的工具包比如tensorflow只会出现在conda list中，不会出现在pip list中，倒过来也一样。</p>
</blockquote>
<hr>
<p><strong>记录一次pytorch指定版本安装过程</strong>：
安装 pytorch 1.1.0和 torchvision 0.3.0，服务器上cuda版本为10.1。</p>
<p>参考官网推荐方式：
<code>conda install pytorch torchvision cuda-toolkit=10.1 -c pytorch</code>
先安装pytorch，采用：
<code>conda install pytorch=1.1.0 -c pytorch</code>
出现的问题是下载pytorch一直显示网络不行，检验是否添加了清华镜像网站作为channel，已经添加了，后来得知得去掉<code>-c pytorch</code>，因为这意味着不会从清华镜像网站下载。但笔者采取的方式是找到pytorch库的链接，先手动下载到本地，再利用
<code>conda install --use-local [pkg]</code>
安装，其中<code>[pkg]</code>表示pytorch库的本地绝对路径，笔者放在<code>~/anaconda3/pkgs/</code>中。</p>
<p>此时在python环境中测试<code>import pytorch</code>，但是报错，信息为<code>libmkl_intel_lp64.so: cannot open shared object file: No such file or directory</code>，参考
<a href="https://www.cnblogs.com/denny402/p/10848506.html">在导入pytorch时libmkl_intel_lp64.so找不到</a>，
搜索到<code>libmkl_intel_lp64.so</code>对应的的路径后，添加到环境变量<code>LD_LIBRARY_PATH</code>中即可解决。</p>
<p>解决了pytorch后，再来处理torchvision，采用<code>-c pytorch</code>会遇到同样的网络问题。去掉后即<code>conda install torchvision=0.3.0</code>下载源不变，故仍有网络问题。同样先下载到本地再安装，<code>import torchvision</code>测试时会显示没有<code>PIL</code>库，查询知<code>PIL</code>库不支持python3，改为安装<code>pillow</code>库即可，即<code>conda install pillow</code>。
另若去掉版本号，即<code>conda isntall torchvision</code>则会自动选择当前最新的pytorch=1.3.0和torchvision=0.4.0，不符合笔者要求，故虽省事，还是得放弃。</p>
<p>另值得一提的是虽然官方上笔者装的版本都对应cuda10.0，服务器上是cuda10.1，但用起来也没问题。另NVIDIA官方cuda10.1有三个版本，10.1表 示10.1.105，10.1 update1表示10.1.168，10.1 update2表示10.1.243。</p>
<hr>
<h3 id="linux%E6%9B%B4%E6%94%B9%E9%BB%98%E8%AE%A4python%E7%89%88%E6%9C%AC">Linux更改默认Python版本</h3>
<pre><code>ls /usr/bin/python*
alias python='/usr/bin/python3.5'
</code></pre>
<hr>
<h3 id="%E6%9F%A5%E7%9C%8B%E7%BD%91%E5%85%B3">查看网关</h3>
<pre><code>route
</code></pre>
<hr>
<h3 id="slurm%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86">slurm集群管理</h3>
<p><code>srun</code>，<code>sbatch</code>和<code>salloc</code>为三大提交任务命令。<code>salloc</code>为交互式，任务结束后不一定及时释放资源，对于按时长收费的集群请慎重；个人喜欢用<code>srun</code>，其与<code>2&gt;&amp;1 |tee [log name]</code>配合，可以在写入文件的同时输出到屏幕上，甚是舒服；<code>sbatch</code> 虽然有<code>-o</code>命令表示输出文件，但使用该命令后不能输出到屏幕上。</p>
<p><code>srun</code>参数众多，如下列出其单字母简称和对应的全称：</p>
<pre class="hljs"><code><div>srun 
-J, --job-name=[job name] 
-p, --partiton=[node partition]
--gres=[资源，如 gpu:2 表示申请两块gpu]
-c，--cpus-per-task=[*]
-n, ntasks-per-node=[*]
-t, --time=[run time]
-q, --qos=[priority level, low/normal/high] 
-o, --output=[output file]
[task command]
</div></code></pre>
<p>以北大未名一号为例，</p>
<pre class="hljs"><code><div>srun --job-name=STL-train --gres=gpu:2 --qos low --time 120:00:00 python -u train.py 2&gt;&amp;1 |tee train.log
</div></code></pre>
<p>查询节点资源：</p>
<pre><code>sinfo
</code></pre>
<p>查询用户任务：</p>
<pre><code>squeue -u [username]
</code></pre>
<p>取消任务：</p>
<pre><code>scancel [JOB_ID]
</code></pre>
<hr>
<h3 id="tmux">tmux</h3>
<p>注：集群上不同节点tmux已建session可能不同。</p>
<p>重命名session:</p>
<pre><code>tmux rename-session -t [old-name] [new-name]
</code></pre>
<hr>
<h3 id="path">$PATH</h3>
<p>配置环境变量，需加入某个应用时，将相应bin文件的路径添加到 ~/.bashrc 文件中。如：</p>
<pre><code>export PATH=&quot;$PATH:/home/hongt/anaconda3/bin&quot;
</code></pre>
<p>其中<code>$PATH</code>即为已有的环境变量；务必使用双引号！</p>
<hr>
<h1 id="mac">Mac</h1>
<h3 id="%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE">常用快捷键</h3>
<p><code>command + shift + 4</code> 部分截屏
<code>control + space</code> 切换输入法
<code>control + command + A</code> QQ截屏
<code>command + C</code> 复制  <code>command + option(alt) + V</code> 剪切粘贴</p>
<hr>
<h3 id="%E6%96%B0%E5%BB%BA%E6%96%87%E4%BB%B6">新建文件</h3>
<p>在终端输入：</p>
<pre><code>touch filename
</code></pre>
<hr>
<h3 id="%E9%9A%90%E8%97%8F%E6%96%87%E4%BB%B6">隐藏文件</h3>
<p>查看隐藏文件：</p>
<pre><code>ls -la
</code></pre>
<p>在访达中可见隐藏文件和.开头文件：</p>
<pre><code>defaults write com.apple.Finder AppleShowAllFiles YES
killall Finder
</code></pre>
<hr>
<h1 id="markdown">Markdown</h1>
<h3 id="markdown-%E8%B6%85%E9%93%BE%E6%8E%A5">Markdown 超链接</h3>
<pre><code>[name](url &quot;hint&quot;)
</code></pre>
<p>在url后面输入 空格加双引号下的提示文字 则鼠标放在该超链接时即会显示该提示文字。</p>
<hr>
<h3 id="markdown-%E7%A9%BA%E6%A0%BC">Markdown 空格</h3>
<p><strong>shift+space</strong> 可切换空格大小（全半角之区别？） (之后再按几个空格就有几个空格，若未这样做按多少个空格都之显示一个空格)。按两个空格即表示换行。</p>
<p>此法对MarkdownPad 2 编辑器有效，而VSCode无效？</p>
<hr>
<h3 id="markdown-%E4%BB%A3%E7%A0%81">Markdown 代码</h3>
<p>` code ` 表示行内代码。</p>
<p>```<br>
code<br>
```<br>
表示行间代码。</p>
<hr>
<h3 id="markdown-%E5%85%AC%E5%BC%8F">Markdown 公式</h3>
<p>在HTML Head编辑器导入相应文件。</p>
<p>基本与Latex语法一致，但\在Markdown中为转义字符，故行内公式<code>$ A $</code> 变为 <strong><code>\\( A \\)</code></strong>。（A代指公式）
用visual studio code编辑则<code>$ $</code> 或 <code>$$ $$</code>即可。</p>
<p>用VSCODE预览公式时没问题，但导出为pdf，html等时公式仍显示源码。解决办法有二，其一为在文档开头写入：</p>
<pre class="hljs"><code><div>&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: &quot;none&quot; });
&lt;/script&gt;
</div></code></pre>
<p>其二为在VSCODE中安装<code>Markdown+Math</code>插件。</p>
<h3 id="markdown-%E5%9B%BE%E7%89%87">Markdown 图片</h3>
<p>插入GitHub上的图片预览不能显示时，把图片链接地址中的 <code>blob</code> 换成 <code>raw</code> 即可！</p>
<h3 id="markdown-%E7%9B%AE%E5%BD%95">Markdown 目录</h3>
<p>用VSCODE编译，将光标置入待插入位置，按<code>Ctrl+Shift+P</code>，在弹出框里输入<code>ctoc</code>即可。</p>
<hr>
<h1 id="latex">LaTex</h1>
<h3 id="vscode-%E7%BC%96%E8%AF%91%E5%99%A8">VSCode 编译器</h3>
<p><code>Ctrl + Alt + B </code> 一次编译
<code>Ctrl + Alt + R</code> 选择recipe，此时才能显示目录、摘要等。
<code>Ctrl + Alt + J</code> 正向查找，即选中LaTex代码后按此快捷键可定位到PDF中的对应文本。</p>
<p>参考：<a href="https://zhuanlan.zhihu.com/p/38178015">使用VSCode编写LaTeX</a>
<a href="https://www.latexstudio.net/archives/12260.html">LaTeX技巧932：如何配置Visual Studio Code作为LaTeX编辑器[新版更新]</a></p>
<h3 id="%E4%B8%80%E4%BA%9B%E7%AC%A6%E5%8F%B7%E4%BB%A3%E7%A0%81">一些符号代码</h3>
<p><code>\pm</code> $\pm$
<code>\equiv</code> $\equiv$
<code>\approx</code> $\approx$
<code>\leq</code> $\leq$
<code>\leqslant</code> $\leqslant$</p>
<p><code>\raggedright</code> 两端对齐</p>
<hr>
<h1 id="others">Others</h1>
<h3 id="paper-writing">paper writing</h3>
<h4 id="%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87">插入图片</h4>
<p>一般插入eps或PDF格式图片，而将jpg、png等格式图片转化为eps格式可借助<code>bmeps</code>命令，在安装了Tex后已具有<code>bmeps</code>模块。在终端中采取如下命令即可（注意写对图片路径，Windows系统下在指定文件夹中按住Shift键再右键选择‘在此处打开pewershell窗口’即可）：
<code>bmeps -c *.png *.eps</code></p>
<hr>
<h3 id="usb%E5%A4%B1%E6%95%88">USB失效</h3>
<p>笔者有一天打开电脑（Windows系统）突然发现所有的USB接口都失效了，导致外接鼠标键盘都失效，插入U盘也读取不了。网上搜了很多教程都不管用，一类方法为电脑在节电模式下会禁用外接USB口等，所以需关闭这些设置，还有卸载USB驱动再重装等（可借助驱动精灵等软件），笔者试了均无果。</p>
<p>开机进入BIOS模式，在<code>System Configuration</code>里有一栏是<code>USB Configuration</code>，勾选上<code>Enable USB Boot Support</code>和<code>Enable External USB Ports</code>；另在<code>Power Management</code>里有一栏是<code>Enable USB Wake Support</code>，勾选上<code>ON</code>。此时开机后便一切恢复岁月静好了！</p>
<p>此次USB失效莫名其妙（系统更新的锅？），按照上述方法搞好后，过了两天又失效了，于是又重复搞了一次，后来就再也没有抽风过。</p>
<p>另很多电脑F1~12键都有另一种对应的功能，如F3除了传统的功能外还可增大音量，默认的是传统功能时要增大音量就得按住<code>fn</code>键再按F3了。在BIOS模式的<code>POST Behavior</code>里有一栏<code>Fn lock</code>的<code>Lock Mode</code>，其有<code>Lock Mode Standard</code>和<code>Lock Mode Secondary</code>，选择一个即可。笔者习惯选择后者，即F3默认为增大音量。</p>
<hr>
<h3 id="server-config202012">server config(~2020.12)</h3>
<p>weiming1：
python3.6.2
torch   0.4.0
torchvision   0.2.1
cv2   3.1.0</p>
<p>PKU163:
Python3.5.2
torch   0.4.1
torchvision   0.2.1
cv2   3.3.0
tensorflow   1.4.0</p>

</body>
</html>
